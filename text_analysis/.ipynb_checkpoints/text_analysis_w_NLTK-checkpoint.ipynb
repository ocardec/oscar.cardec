{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis with NLTK and Tableau Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a Data Analyst, BI Analyst, Data Miner, ML Engineer, etc. text analysis could result in one of the handiest tools of your toolbox. In simple words, text analysis is about parsing a string or text file with the objective of extracting key characteristics, facts, or trends from within the context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"Using Text Analysis is one of the first steps in many data-driven approaches, as the process extracts machine-readable facts from large bodies of texts and allows these facts to be further entered automatically into a database or a spreadsheet. The database or the spreadsheet are then used to analyze the data for trends, to give a natural language summary, or may be used for indexing purposes in Information Retrieval applications\" [ontotext.com](https://www.ontotext.com/knowledgehub/fundamentals/text-analysis/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "*Given unstructured text data, process the data, and create valuable business analytics.  Create a managerial report identifying the patterns and recommendations uncovered in the data.* \n",
    "\n",
    "You want to choose readily available text which recurred over at least three time periods, spaced some distance apart. You want to make sure you have at least several thousand words of text for each time period, and you want something which will change noticeably over that time period. \n",
    "\n",
    "For this example, I've selected the U.S. National Security Strategy for the years of [1996](https://nssarchive.us/wp-content/uploads/2020/04/1996.pdf), [2002](https://nssarchive.us/wp-content/uploads/2020/04/1996.pdf), and [2017](http://nssarchive.us/wp-content/uploads/2020/04/2017.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">##### Text analysis is about parsing a string or text file with the objective of extracting characteristics, facts, or trends from the context. \n",
    "\n",
    "__1st Step:__  Open the text file (ie., nss1996.txt), create basic counters, and dictionary, split the lines as words, and lowercase all contained words. Note: Starter Code - Based on Toby Donaldson's Python: Visual QuickStart Guide function print_file_stats (location 5347). Modified by OC on 7 Jul 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program to open a text file named 'nss1996.txt' give a word count of all the words in the file and give the top 30 words. Note: This code assumes the following have been imported:\n",
    "- import string\n",
    "- import nltk\n",
    "- nltk.download('stopwords')\n",
    "- from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    fhand = open('nss1996.txt', 'r').read()   #open the file\n",
    "    num_chars = len(fhand)                    #count characters \n",
    "    num_lines = fhand.count('\\n')             #count lines\n",
    "    d = dict()                                #create a list\n",
    "    words = fhand.split()                     #split lines\n",
    "    words = [word.lower() for word in words]  #lowercase words\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2nd Step:__ Filter out punctuation, stop words, and any other additional word not excluded by NLTK stop-words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # extra junky or particular words to exclude\n",
    "    words = [word.replace('united','') for word in words]\n",
    "    words = [word.replace('states','') for word in words]\n",
    "    words = [word.replace('also','') for word in words]\n",
    "    words = [word.replace('use','') for word in words]\n",
    "    words = [word.replace('make','') for word in words]\n",
    "    words = [word.replace('must','') for word in words]\n",
    "    words = [word.replace('new','') for word in words]\n",
    "    words = [word.replace('every','') for word in words]\n",
    "    # filter out punctuation \n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3rd Step:__ Set the if-else loop to capture unique words, and count them. Update the number of words total and append new words to the list. Establish your print statements and list format, in my case, I wan the top-30 words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Set the if-else loop to capture unique words, and count them. \n",
    "    # Update number of words total, and append new words to the list. st. s = sum(d[w] for w in d)\n",
    "\n",
    "    lst = [(d[w], w) for w in d]\n",
    "    lst.sort()\n",
    "    lst.reverse()\n",
    "\n",
    "    print('Total number of characters = ' + str(num_chars))\n",
    "    print('Total number of lines = ' + str(num_lines))\n",
    "    print('Total number of words = ' + str(num_words))\n",
    "\n",
    "    print('\\n The 30 most frequent words are: \\n')\n",
    "\n",
    "    i = 1\n",
    "    for count, word in lst[:30]:\n",
    "        print('%2s.  %4s %s' % (i, count, word))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Total number of characters = 207517\n",
    "    Total number of lines = 642\n",
    "    Total number of words = 14350\n",
    "\n",
    "     The 30 most frequent words are: \n",
    "\n",
    "     1.   151 security\n",
    "     2.   134 international\n",
    "     3.   128 economic\n",
    "     4.    96 military\n",
    "     5.    96 forces\n",
    "     6.    88 peace\n",
    "     7.    80 American\n",
    "     8.    77 support\n",
    "     9.    74 national\n",
    "    10.    69 nations ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Repeat the process for your alternate text files.  Aggregate your generated lists, in my case, I combined my three lists as a CSV file under the following headings, then imported into Tableau. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary Excerpt  \n",
    "\n",
    "The analysis highlights some of the priorities and lines of efforts of the United States between 1996 and 2017.  Three central conclusions are evident in this assessment: 1. The U.S. pivoted from a cold-war era to a global war on terrorism, to homeland-focused.  2. There was a shift of priorities immediately after the September 11, 2001, Word Trade Center attack.  3. For the last 3 years, the U.S. has shifted between its mission areas, moving from previous administrations’ foreign policies and strategies like global trade and world politics to America-centric and new economic goals.  \n",
    "\n",
    "Driven by these findings, absence of words across these reports, and perceived inclinations, the immediate recommendations include  1. To reassess the U.S. Government posture in relation to the international community and avoid complete isolation, which could further cripple the international order.  2. To reassess its current stance in relation to the North Atlantic Treaty Organization objectives.  3.  To deliberately re-engage supporting fair and equitable human-rights and democratic processes across the globe, knowing that “the progress of the American people relies on a balanced world”.  \n",
    "\n",
    "The first depiction of recurring words across these NSS reports (figure 1.0) exemplifies key-policy differences between these years.Case in point, the 1996 NSS accentuates economic, international, and military-forces, while 2002, is most predominant on global, trade, and international. Subsequently, in 2017, economic re-appears, along with American, and partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "![Philadelphia's Magic Gardens. This place was so cool!](/assets/images/philly-magic-gardens.jpg \"Philadelphia's Magic Gardens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
